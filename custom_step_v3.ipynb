{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import arviz as az\n",
    "import xarray as xr\n",
    "from pymc.step_methods.arraystep import ArrayStep\n",
    "from pymc.util import get_value_vars_from_user_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 3137\n",
    "rng = np.random.default_rng(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quap(vars, start=None, draws=1_000, chains=1):\n",
    "\n",
    "    map = pm.find_MAP(vars=vars, start=start)\n",
    "\n",
    "    m = pm.modelcontext(None)\n",
    "\n",
    "    for var in vars:\n",
    "        if m.rvs_to_transforms[var] is not None:\n",
    "            m.rvs_to_transforms[var] = None\n",
    "            var_value = m.rvs_to_values[var]\n",
    "            var_value.name = var.name\n",
    "\n",
    "    H = pm.find_hessian(map, vars=vars)\n",
    "    cov = np.linalg.inv(H)\n",
    "    mean = np.concatenate([np.atleast_1d(map[v.name]) for v in vars])\n",
    "    posterior = st.multivariate_normal(mean=mean, cov=cov)\n",
    "\n",
    "    samples = rng.multivariate_normal(mean, cov, size=(chains, draws))\n",
    "\n",
    "    data_vars = {}\n",
    "    for i, var in enumerate(vars):\n",
    "        data_vars[str(var)] = xr.DataArray(samples[:, :, i], dims=(\"chain\", \"draw\"))\n",
    "\n",
    "    coords = {\"chain\": np.arange(chains), \"draw\": np.arange(draws)}\n",
    "    ds = xr.Dataset(data_vars, coords=coords)\n",
    "\n",
    "    idata = az.convert_to_inference_data(ds)\n",
    "\n",
    "    return idata, posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([2642, 3503, 4358]*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8585c6e01ef1473896c448ea19f2e1b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/learningbayesianstatistics/lib/python3.11/site-packages/pymc/model/core.py:565: FutureWarning: Model.model property is deprecated. Just use Model.\n",
      "  warnings.warn(\"Model.model property is deprecated. Just use Model.\", FutureWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/learningbayesianstatistics/lib/python3.11/site-packages/pytensor/configparser.py:47: FutureWarning: hessian will stop negating the output in a future version of PyMC.\n",
      "To suppress this warning set `negate_output=False`\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as m: \n",
    "  logsigma = pm.Uniform(\"logsigma\", 1, 100)\n",
    "  mu = pm.Uniform(\"mu\", -10000, 10000) \n",
    "  yobs = pm.Normal(\"y\", mu=mu, sigma=pm.math.exp(logsigma), observed=y)\n",
    "  idata, posterior = quap([mu, logsigma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuadraticApproximation(ArrayStep):\n",
    "    def __init__(self, vars, model, **kwargs):\n",
    "        self.model = model\n",
    "        self.vars = vars\n",
    "        self.varnames = [var.name for var in vars]\n",
    "        \n",
    "        # Compute mode and covariance\n",
    "        self.mode, self.covariance = self._compute_mode_and_covariance()\n",
    "\n",
    "        # Get the log-probability functions\n",
    "        fs = [model.logp(var) for var in vars]\n",
    "                \n",
    "        vars = get_value_vars_from_user_vars(vars, model)\n",
    "        \n",
    "\n",
    "\n",
    "        # Create necessary function sets for pymc\n",
    "        # super().__init__(vars, [self._logp_fn], **kwargs)\n",
    "        super().__init__(vars, fs, **kwargs)\n",
    "      \n",
    "    def _point_to_array(self, point):\n",
    "        return np.array([point[varname] for varname in self.varnames])\n",
    "    \n",
    "    def _array_to_point(self, array):\n",
    "        return {varname: val for varname, val in zip(self.varnames, array)}\n",
    "\n",
    "    def _logp_fn(self, x):\n",
    "        point = self._array_to_point(x)\n",
    "        return self.model.logp(point)\n",
    "    \n",
    "    def _compute_mode_and_covariance(self):\n",
    "        # Find the MAP estimate (mode of the posterior)\n",
    "        map = pm.find_MAP(vars=self.vars)\n",
    "\n",
    "        m = pm.modelcontext(None)\n",
    "\n",
    "        for var in self.vars:\n",
    "            if m.rvs_to_transforms[var] is not None:\n",
    "                m.rvs_to_transforms[var] = None\n",
    "                # change name so that we can use `map[var]` value\n",
    "                var_value = m.rvs_to_values[var]\n",
    "                var_value.name = var.name\n",
    "\n",
    "        H = pm.find_hessian(map, vars=self.vars)\n",
    "        cov = np.linalg.inv(H)\n",
    "        mean = np.concatenate([np.atleast_1d(map[v.name]) for v in self.vars])\n",
    "        \n",
    "        return mean, cov\n",
    "\n",
    "    def astep(self, q0, logp):\n",
    "        # Generate a sample from the multivariate Gaussian approximation\n",
    "        sample = np.random.multivariate_normal(self.mode, self.covariance)\n",
    "        return sample, []\n",
    "\n",
    "# Example usage:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "785ec52a6e274e178babbb5bc83fd295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/learningbayesianstatistics/lib/python3.11/site-packages/pymc/model/core.py:565: FutureWarning: Model.model property is deprecated. Just use Model.\n",
      "  warnings.warn(\"Model.model property is deprecated. Just use Model.\", FutureWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/learningbayesianstatistics/lib/python3.11/site-packages/pytensor/configparser.py:47: FutureWarning: hessian will stop negating the output in a future version of PyMC.\n",
      "To suppress this warning set `negate_output=False`\n",
      "  return f(*args, **kwargs)\n",
      "Sequential sampling (1 chains in 1 job)\n",
      "QuadraticApproximation: [mu, logsigma]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa83f243a404554bc6e4beb96dd9204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "QuadraticApproximation.astep() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Instantiate and use the custom sampler\u001b[39;00m\n\u001b[1;32m     10\u001b[0m custom_step \u001b[38;5;241m=\u001b[39m QuadraticApproximation(\u001b[38;5;28mvars\u001b[39m\u001b[38;5;241m=\u001b[39m[mu, logsigma], model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m---> 11\u001b[0m trace \u001b[38;5;241m=\u001b[39m \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_step\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/learningbayesianstatistics/lib/python3.11/site-packages/pymc/sampling/mcmc.py:824\u001b[0m, in \u001b[0;36msample\u001b[0;34m(draws, tune, chains, cores, random_seed, progressbar, progressbar_theme, step, var_names, nuts_sampler, initvals, init, jitter_max_retries, n_init, trace, discard_tuned_samples, compute_convergence_checks, keep_warning_stat, return_inferencedata, idata_kwargs, nuts_sampler_kwargs, callback, mp_ctx, model, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m         _log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSequential sampling (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchains\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m chains in 1 job)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    823\u001b[0m         _print_step_hierarchy(step)\n\u001b[0;32m--> 824\u001b[0m         \u001b[43m_sample_many\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msample_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m t_sampling \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t_start\n\u001b[1;32m    828\u001b[0m \u001b[38;5;66;03m# Packaging, validating and returning the result was extracted\u001b[39;00m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# into a function to make it easier to test and refactor.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/learningbayesianstatistics/lib/python3.11/site-packages/pymc/sampling/mcmc.py:966\u001b[0m, in \u001b[0;36m_sample_many\u001b[0;34m(draws, chains, traces, start, random_seed, step, callback, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Samples all chains sequentially.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m \n\u001b[1;32m    952\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[38;5;124;03m    Step function\u001b[39;00m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    965\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(chains):\n\u001b[0;32m--> 966\u001b[0m     \u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdraws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdraws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraces\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/learningbayesianstatistics/lib/python3.11/site-packages/pymc/sampling/mcmc.py:1039\u001b[0m, in \u001b[0;36m_sample\u001b[0;34m(chain, progressbar, random_seed, start, draws, step, trace, tune, model, progressbar_theme, callback, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1038\u001b[0m     task \u001b[38;5;241m=\u001b[39m progress\u001b[38;5;241m.\u001b[39madd_task(_desc\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_pbar_data), total\u001b[38;5;241m=\u001b[39mdraws, visible\u001b[38;5;241m=\u001b[39mprogressbar)\n\u001b[0;32m-> 1039\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiverging\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msampling_gen\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mskip_first\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdiverging\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_pbar_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdivergences\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/learningbayesianstatistics/lib/python3.11/site-packages/pymc/sampling/mcmc.py:1107\u001b[0m, in \u001b[0;36m_iter_sample\u001b[0;34m(draws, step, start, trace, chain, tune, model, random_seed, callback)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m tune:\n\u001b[1;32m   1106\u001b[0m     step\u001b[38;5;241m.\u001b[39mstop_tuning()\n\u001b[0;32m-> 1107\u001b[0m point, stats \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1108\u001b[0m trace\u001b[38;5;241m.\u001b[39mrecord(point, stats)\n\u001b[1;32m   1109\u001b[0m log_warning_stats(stats)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/learningbayesianstatistics/lib/python3.11/site-packages/pymc/step_methods/arraystep.py:59\u001b[0m, in \u001b[0;36mArrayStep.step\u001b[0;34m(self, point)\u001b[0m\n\u001b[1;32m     57\u001b[0m var_dict \u001b[38;5;241m=\u001b[39m {cast(\u001b[38;5;28mstr\u001b[39m, v\u001b[38;5;241m.\u001b[39mname): point[cast(\u001b[38;5;28mstr\u001b[39m, v\u001b[38;5;241m.\u001b[39mname)] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvars}\n\u001b[1;32m     58\u001b[0m apoint \u001b[38;5;241m=\u001b[39m DictToArrayBijection\u001b[38;5;241m.\u001b[39mmap(var_dict)\n\u001b[0;32m---> 59\u001b[0m apoint_new, stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpartial_funcs_and_point\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(apoint_new, RaveledVars):\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# We assume that the mapping has stayed the same\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     apoint_new \u001b[38;5;241m=\u001b[39m RaveledVars(apoint_new, apoint\u001b[38;5;241m.\u001b[39mpoint_map_info)\n",
      "\u001b[0;31mTypeError\u001b[0m: QuadraticApproximation.astep() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "with pm.Model() as model:\n",
    "    # Define a simple Gaussian model\n",
    "    logsigma = pm.Uniform(\"logsigma\", 1, 100)\n",
    "    mu = pm.Uniform(\"mu\", -10000, 10000) \n",
    "    yobs = pm.Normal(\"y\", mu=mu, sigma=pm.math.exp(logsigma), observed=y)\n",
    "        \n",
    "    \n",
    "\n",
    "    # Instantiate and use the custom sampler\n",
    "    custom_step = QuadraticApproximation(vars=[mu, logsigma], model=model)\n",
    "    trace = pm.sample(1000, chains=1,step=custom_step)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_5.5%</th>\n",
       "      <th>hdi_94.5%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logsigma</th>\n",
       "      <td>6.55</td>\n",
       "      <td>0.13</td>\n",
       "      <td>6.35</td>\n",
       "      <td>6.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mu</th>\n",
       "      <td>3504.25</td>\n",
       "      <td>121.11</td>\n",
       "      <td>3325.77</td>\n",
       "      <td>3705.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             mean      sd  hdi_5.5%  hdi_94.5%\n",
       "logsigma     6.55    0.13      6.35       6.77\n",
       "mu        3504.25  121.11   3325.77    3705.12"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(trace, kind=\"stats\", hdi_prob=0.89).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_5.5%</th>\n",
       "      <th>hdi_94.5%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mu</th>\n",
       "      <td>3503.71</td>\n",
       "      <td>128.76</td>\n",
       "      <td>3320.47</td>\n",
       "      <td>3724.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logsigma</th>\n",
       "      <td>6.55</td>\n",
       "      <td>0.13</td>\n",
       "      <td>6.37</td>\n",
       "      <td>6.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             mean      sd  hdi_5.5%  hdi_94.5%\n",
       "mu        3503.71  128.76   3320.47    3724.41\n",
       "logsigma     6.55    0.13      6.37       6.76"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(idata, kind=\"stats\", hdi_prob=0.89).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learningbayesianstatistics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
